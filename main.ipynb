{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier Adversarial Attack\n",
    "This notebook demonstrates various adversarial attack methods on an image classifier using a pre-trained ResNet50 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "network = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "with open('data/mapping.txt', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        input_image = Image.open(\"data/images/\" + row[0])\n",
    "        row.append(input_image)\n",
    "        images.append(row)\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ImageNet Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/imagenet1000_clsid_to_human.json') as json_file:\n",
    "    class_idx = json.load(json_file)\n",
    "    labels = {int(key): value for key, value in class_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(5,2, dpi=200) \n",
    "for i in range(10):\n",
    "    y = i // 5\n",
    "    x = i % 5\n",
    "    input_image = Image.open(\"data/images/\" + images[i][0])\n",
    "    axarr[x, y].axes.get_xaxis().set_visible(False)\n",
    "    axarr[x, y].axes.get_yaxis().set_visible(False)\n",
    "    axarr[x, y].imshow(images[i][3])\n",
    "    axarr[x, y].set_title(images[i][1], fontsize=10)\n",
    "    plt.subplots_adjust(wspace=None, hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Transformation and Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transform_image(image):\n",
    "    centre_crop = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    input_tensor = centre_crop(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    return input_batch\n",
    "\n",
    "def inverse_transform(image):\n",
    "    inv = transforms.Compose([ \n",
    "        transforms.Normalize([ 0., 0., 0. ],[ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "        transforms.Normalize([ -0.485, -0.456, -0.406 ],[ 1., 1., 1. ]),])\n",
    "    return inv(image)\n",
    "\n",
    "def predict(image, network, raw_image=True):\n",
    "    #use raw image, it will transform it\n",
    "    #return: array of probability for each class\n",
    "    input_batch = image\n",
    "    if raw_image:\n",
    "        input_batch = transform_image(image)\n",
    "    with torch.no_grad():\n",
    "        network.eval()\n",
    "        prediction = network(input_batch)  \n",
    "    return prediction.data.numpy()\n",
    "\n",
    "def probabilty_of_class(image, class_index, network, raw_image=True):\n",
    "    prediction = predict(image, network, raw_image)\n",
    "    return prediction[0,class_index]\n",
    "\n",
    "def get_most_probable_class(image, network, raw_image=True):\n",
    "    #returns index and class name\n",
    "    prediction = predict(image, network, raw_image)\n",
    "    index = prediction.argmax()\n",
    "    return(index, labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Transformed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(5,2, dpi=200) \n",
    "to_image = transforms.ToPILImage()\n",
    "for i in range(10):\n",
    "    y = i // 5\n",
    "    x = i % 5\n",
    "    input_image = transform_image(images[i][3])\n",
    "    axarr[x, y].imshow(inverse_transform(input_image[0]).permute(1, 2, 0).detach().numpy() )\n",
    "    axarr[x, y].axes.get_xaxis().set_visible(False)\n",
    "    axarr[x, y].axes.get_yaxis().set_visible(False)\n",
    "    index, label = get_most_probable_class(input_image, network, False)\n",
    "    axarr[x, y].set_title(label.split(\",\")[0], fontsize=10)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in images:\n",
    "    i[3] = transform_image(i[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Most Probable Class for a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "get_most_probable_class(images[0][3], network, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Adversarial Attack Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fast_gradient_attack(image, correct_prediction_index, epsilon, network_to_attack, iteration_count = 1):\n",
    "    #return image, probability before and probabilty \n",
    "    changed_image = image\n",
    "    prev_prob = probabilty_of_class(changed_image, correct_prediction_index, network_to_attack, False)\n",
    "    if iteration_count == -1:\n",
    "        iteration_count = 100\n",
    "    for i in tqdm(range(iteration_count)):\n",
    "        predict_index = get_most_probable_class(changed_image, network, False)[0]\n",
    "        if predict_index != correct_prediction_index:\n",
    "            break\n",
    "        network.eval()\n",
    "        image.requires_grad = True\n",
    "        prediction = network_to_attack(image)\n",
    "\n",
    "        loss = F.nll_loss(prediction, torch.tensor([correct_prediction_index]))\n",
    "        network.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        data_grad = image.grad.data\n",
    "\n",
    "        changed_image = changed_image + epsilon * data_grad.sign()\n",
    "\n",
    "        changed_image = changed_image.clamp(-3, 3)\n",
    "        new_prob = probabilty_of_class(changed_image, correct_prediction_index, network_to_attack, False)\n",
    "    return (changed_image, prev_prob, new_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def simba_attack(image, correct_prediction_index, epsilon, network_to_attack, iteration_count = 1000):\n",
    "    result = image\n",
    "    result.requires_grad = False\n",
    "    size = result.shape[1] * result.shape[2] * result.shape[3]\n",
    "    perm = torch.randperm(size)\n",
    "    prev_prob = probabilty_of_class(result, correct_prediction_index, network_to_attack, False)\n",
    "    start_prob = prev_prob\n",
    "    if iteration_count == -1:\n",
    "        iteration_count = 25000\n",
    "    for i in tqdm(range(iteration_count)):\n",
    "        predict_index = get_most_probable_class(result, network, False)[0]\n",
    "        if predict_index != correct_prediction_index:\n",
    "            break\n",
    "        to_add = torch.zeros(size)\n",
    "        to_add[perm[i]] = epsilon\n",
    "        to_add = to_add.view(result[0].size()).clamp(-3, 3)\n",
    "        result[0] += to_add\n",
    "        new_prob = probabilty_of_class(result, correct_prediction_index, network_to_attack, False)\n",
    "        if(new_prob < prev_prob):\n",
    "            prev_prob = new_prob\n",
    "        else:\n",
    "            changed_image = result\n",
    "            changed_image[0] -= 2*to_add\n",
    "            new_prob = probabilty_of_class(result, correct_prediction_index, network_to_attack, False)\n",
    "            if(new_prob < prev_prob):\n",
    "                prev_prob = new_prob\n",
    "            else:\n",
    "                result[0] += to_add\n",
    "    return (result, start_prob, prev_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepFool(input_batch, correct_prediction_index, epsilon, network_to_attack, iteration_count = 1):\n",
    "    batch = input_batch.detach().clone()\n",
    "    batch.requires_grad = True\n",
    "    network.eval()\n",
    "    prediction = network(batch)\n",
    "    prediction_idx = correct_prediction_index\n",
    "    new_prediction_idx = prediction_idx\n",
    "    iterations = 0\n",
    "    prev_prob = probabilty_of_class(input_batch, correct_prediction_index, network_to_attack, False)\n",
    "    while correct_prediction_index == new_prediction_idx:\n",
    "        prediction_value = prediction[0,prediction_idx]\n",
    "        batch.retain_grad()\n",
    "        prediction_value.backward(retain_graph=True)\n",
    "        grad_preciction = batch.grad.detach().clone()\n",
    "        batch.grad.data.zero_()\n",
    "\n",
    "        w = torch.zeros_like(batch)\n",
    "        f = torch.empty([1])\n",
    "        ratio = 0\n",
    "        n = prediction.shape[1]\n",
    "\n",
    "        for c in tqdm(range(n)):\n",
    "            if c != prediction_idx:\n",
    "                prediction_c = prediction[0,c]\n",
    "                batch.retain_grad()\n",
    "                prediction_c.backward(retain_graph=True)\n",
    "                grad_c = batch.grad.detach().clone()\n",
    "                batch.grad.data.zero_()\n",
    "                w_ = grad_c - grad_preciction\n",
    "                f_ = prediction_c - prediction_value\n",
    "                if c == 0 or (prediction_idx == 0 and c == 1):\n",
    "                    f = f_\n",
    "                    w = w_\n",
    "                    ratio = torch.abs(f_) / torch.linalg.norm(w_)\n",
    "                elif torch.abs(f_) / torch.linalg.norm(w_) < ratio:\n",
    "                    f = f_\n",
    "                    w = w_\n",
    "                    ratio = torch.abs(f_) / torch.linalg.norm(w_)\n",
    "\n",
    "        new_batch = batch.detach().clone()\n",
    "        new_batch.requires_grad_(False)\n",
    "        new_batch += ratio * (w > 0).type(torch.float32) * torch.abs(w)\n",
    "        new_batch -= ratio * (w < 0).type(torch.float32) * torch.abs(w)\n",
    "        new_batch.requires_grad_(True)\n",
    "\n",
    "        network_to_attack.eval()\n",
    "        prediction = network_to_attack(new_batch)\n",
    "        new_prediction_idx = prediction.data.numpy().argmax()\n",
    "        batch = new_batch\n",
    "        iterations+=1\n",
    "        new_prob = probabilty_of_class(batch, correct_prediction_index, network_to_attack, False)\n",
    "    return (batch, prev_prob, new_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will skip this part. It takes hours to compute as can be seen from the loading bar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attacks_algorithms_name = ['fast gradient attack', 'simba', 'DeepFool']\n",
    "attacks_algorithms = [fast_gradient_attack, simba_attack, DeepFool]\n",
    "result = []\n",
    "for i in range(len(images)):\n",
    "    result.append([])\n",
    "    for j in range(len(attacks_algorithms)):\n",
    "        res, prev, new = attacks_algorithms[j](images[i][3], int(images[i][2]), 0.3, network, -1)\n",
    "        result[i].append((attacks_algorithms_name[j], res, prev, new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Adversarial Attack Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(10,len(attacks_algorithms)+1, dpi=650) \n",
    "to_image = transforms.ToPILImage()\n",
    "for i in range(10):\n",
    "    axarr[i, 0].imshow(inverse_transform(images[i][3][0]).permute(1, 2, 0).detach().numpy() )\n",
    "    axarr[i, 0].axes.get_xaxis().set_visible(False)\n",
    "    axarr[i, 0].axes.get_yaxis().set_visible(False)\n",
    "    index, label = get_most_probable_class(images[i][3], network, False)\n",
    "    axarr[i, 0].set_title(label.split(\",\")[0], fontsize=5)\n",
    "    for j in range(len(attacks_algorithms)):\n",
    "        axarr[i, j+1].imshow(inverse_transform(result[i][j][1][0]).permute(1, 2, 0).detach().numpy() )\n",
    "        axarr[i, j+1].axes.get_xaxis().set_visible(False)\n",
    "        axarr[i, j+1].axes.get_yaxis().set_visible(False)\n",
    "        index, label = get_most_probable_class(result[i][j][1], network, False)\n",
    "        axarr[i, j+1].set_title(label.split(\",\")[0], fontsize=5)\n",
    "        f.subplots_adjust(wspace=-0.8, hspace = 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_closest(prediction,prediction_idx):\n",
    "    prediction = torch.squeeze(prediction)\n",
    "    s = torch.argsort(prediction,descending=True)\n",
    "    loss = 0\n",
    "    if prediction_idx == s[0]:\n",
    "        loss = prediction[s[0]] - prediction[s[1]]\n",
    "    else:\n",
    "        loss = prediction[prediction_idx] - prediction[s[0]]\n",
    "    return loss\n",
    "\n",
    "def log_loss_closest(prediction,prediction_idx):\n",
    "    prediction = torch.squeeze(prediction)\n",
    "    s = torch.argsort(prediction,descending=True)\n",
    "    loss = 0\n",
    "    if prediction_idx == s[0]:\n",
    "        loss = torch.log(prediction[s[0]]) - torch.log(prediction[s[1]])\n",
    "    else:\n",
    "        loss = torch.log(prediction[prediction_idx]) - torch.log(prediction[s[0]])\n",
    "    return loss\n",
    "\n",
    "def log_loss(prediction,prediction_idx):\n",
    "    return -torch.log(prediction[0,prediction_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define SPSA Attack Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SPSA(input_batch, network, it, N, eps, delta, alpha):\n",
    "    x = copy.deepcopy(input_batch)\n",
    "    prediction_idx = 0\n",
    "    new_prediction_idx = 0\n",
    "    print(\"Shape: \", input_batch.shape)\n",
    "    with torch.no_grad():\n",
    "        network.eval()\n",
    "        prediction = network(x)\n",
    "        prediction_idx = torch.argmax(prediction)\n",
    "        new_prediction_idx = prediction_idx\n",
    "\n",
    "        print(type(new_prediction_idx))\n",
    "        print(type(prediction_idx))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        while new_prediction_idx == prediction_idx:\n",
    "            print('i',i)\n",
    "            i +=1\n",
    "            g = torch.zeros(input_batch.shape)\n",
    "            for j in range(100):\n",
    "                #print('j',j)\n",
    "                v = torch.randint(2, input_batch.shape)\n",
    "                v[v == 0] = -1\n",
    "\n",
    "                network.eval()\n",
    "                p1 = network(x + delta * v)\n",
    "                p2 = network(x - delta * v)\n",
    "                \n",
    "                l1 = log_loss_closest(p1, prediction_idx)\n",
    "                l2 = log_loss_closest(p2, prediction_idx)\n",
    "                print(\"Loses: \", l1, l2)\n",
    "                print(\"Value loss shape: \", (l1 - l2).shape)\n",
    "                print(v.shape)\n",
    "                gj = (log_loss(p1, prediction_idx) - log_loss(p2, prediction_idx)) / (2 * delta * v)\n",
    "                print(gj.shape)\n",
    "                \n",
    "                g += gj\n",
    "            x = x - (alpha / N) * gj\n",
    "\n",
    "            n = torch.linalg.norm(x - input_batch)\n",
    "            print(n)\n",
    "            if n >= eps:\n",
    "                x = input_batch + (x - input_batch) * eps / torch.linalg.norm(x - input_batch)\n",
    "            \n",
    "            new_prediction_idx = torch.argmax(network(x))\n",
    "            print(new_prediction_idx)\n",
    "\n",
    "    return prediction_idx, new_prediction_idx, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# f, axarr = plt.subplots(5,3, dpi=400) \n",
    "# to_image = transforms.ToPILImage()\n",
    "# for i in range(5, 10):\n",
    "#     axarr[i-5, 0].imshow(to_image(inverse_transform(images[i][3][0])) )\n",
    "#     axarr[i-5, 0].axes.get_xaxis().set_visible(False)\n",
    "#     axarr[i-5, 0].axes.get_yaxis().set_visible(False)\n",
    "#     index, label = get_most_probable_class(images[i][3], network, False)\n",
    "#     axarr[i-5, 0].set_title(label.split(\",\")[0], fontsize=10)\n",
    "#     for j in range(len(attacks_algorithms)):\n",
    "#         axarr[i-5, j+1].imshow(inverse_transform(result[i][j][1][0]).permute(1, 2, 0).detach().numpy() )\n",
    "#         axarr[i-5, j+1].axes.get_xaxis().set_visible(False)\n",
    "#         axarr[i-5, j+1].axes.get_yaxis().set_visible(False)\n",
    "#         index, label = get_most_probable_class(result[i][j][1], network, False)\n",
    "#         axarr[i-5, j+1].set_title(label.split(\",\")[0], fontsize=10)\n",
    "#         plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     for j in range(len(attacks_algorithms)):\n",
    "#         to_image(inverse_transform(result[i][j][1][0])).save(\"results/\" + attacks_algorithms_name[j] + \"_\" + str(i)+\".png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# f, axarr = plt.subplots(5,3, dpi=400) \n",
    "# to_image = transforms.ToPILImage()\n",
    "# for i in range(5, 10):\n",
    "#     baseImage = to_image(inverse_transform(images[i][3][0]))\n",
    "#     axarr[i-5, 0].imshow( baseImage )\n",
    "#     axarr[i-5, 0].axes.get_xaxis().set_visible(False)\n",
    "#     axarr[i-5, 0].axes.get_yaxis().set_visible(False)\n",
    "#     index, label = get_most_probable_class(images[i][3], network, False)\n",
    "#     axarr[i-5, 0].set_title(label.split(\",\")[0], fontsize=10)\n",
    "#     for j in range(1):\n",
    "#         axarr[i-5, j+1].imshow(inverse_transform(result[i][j][1][0]).permute(1, 2, 0).detach().numpy() )\n",
    "#         axarr[i-5, j+1].axes.get_xaxis().set_visible(False)\n",
    "#         axarr[i-5, j+1].axes.get_yaxis().set_visible(False)\n",
    "#         index, label = get_most_probable_class(result[i][j][1], network, False)\n",
    "#         axarr[i-5, j+1].set_title(label.split(\",\")[0], fontsize=10)\n",
    "#         axarr[i-5, j+2].imshow(0.05 * np.abs(inverse_transform(result[i][j+1][1][0]).permute(1, 2, 0).detach().numpy() - baseImage))\n",
    "#         axarr[i-5, j+2].axes.get_xaxis().set_visible(False)\n",
    "#         axarr[i-5, j+2].axes.get_yaxis().set_visible(False)\n",
    "#         index, label = get_most_probable_class(result[i][j][1], network, False)\n",
    "#         axarr[i-5, j+2].set_title(label.split(\",\")[0], fontsize=10)\n",
    "#         plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     for j in range(len(attacks_algorithms)):\n",
    "#         baseImage = inverse_transform(images[i][3][0].detach())\n",
    "#         resultImage = np.clip(inverse_transform(result[i][j][1][0].detach()), 0, 1)\n",
    "#         image_to_write = np.abs(baseImage-resultImage)\n",
    "#         print(image_to_write.shape)\n",
    "#         image_to_write = to_image(1.0 - image_to_write / torch.amax(image_to_write))\n",
    "#         image_to_write.save(\"results/\" + attacks_algorithms_name[j] + \"_diffs_\" + str(i)+\".png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(deepFoolDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(deepFoolDifference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.std(deepFoolDifference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statisticValue = []\n",
    "# for j in range(len(attacks_algorithms)):\n",
    "#     diffs = []\n",
    "#     for i in range(10):\n",
    "#         baseImage = inverse_transform(images[i][3][0].detach())\n",
    "#         resultImage = np.clip(inverse_transform(result[i][j][1][0].detach()), 0, 1)\n",
    "#         diffs.append(torch.norm(resultImage))\n",
    "#     print(attacks_algorithms_name[j], \". mean: \", np.mean(diffs), \"std: \", np.std(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_gradient_iter = [1, 3, 1, 1, 1, 1, 1, 1, 3, 1]\n",
    "# fast_gradient_time = [1, 2, 1, 1, 1, 1, 1, 1, 3, 1]\n",
    "# simba_iter = [1353, 11344, 14466, 8009, 1355, 335, 5709, 4271, 2161, 4419]\n",
    "# simba_time = [247, 2203, 3084, 1811, 352, 90, 1583, 1157, 400, 833]\n",
    "# deepfool_iter = [1001, 2002, 2002, 1001, 1001, 1001, 1001, 1001, 1001, 1001]\n",
    "# deepfool_time = [168, 511, 512, 165, 178, 184, 174, 163, 166, 162]\n",
    "# print(\"Fsgm iter: \", np.mean(fast_gradient_iter))\n",
    "# print(\"Simba iter: \", np.mean(simba_iter))\n",
    "# print(\"DeepFool iter: \", np.mean(deepfool_iter))\n",
    "# print(\"Fsgm time: \", np.mean(fast_gradient_time))\n",
    "# print(\"Simba time: \", np.mean(simba_time))\n",
    "# print(\"Deepfool time: \", np.mean(deepfool_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advattack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
